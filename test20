import boto3
import json
import time
import logging

athena = boto3.client("athena", region_name="us-east-1")
s3 = boto3.client("s3")

DATABASE = "painel-monitoracao"
WORKGROUP = "painel_monitoracao"
OUTPUT_BUCKET = "s3://painel-monitoracao-administrativo-dados/athena_lambda/"
CACHE_BUCKET = "painel-monitoracao-administrativo-dados"
CACHE_PREFIX = "api_cache/dados_part_"

QUERY = """
SELECT 
    num_chamado,
    equipe,
    gerente_equipe,
    dpto_equipe,
    coord_dpto_equipe,
    ger_dpto_equipe,
    dpto_ger_equipe,
    severidade,
    dat_abertura,
    dat_status_concluido,
    dat_fechamento,
    data_normalizacao,
    status,
    classificacao,
    dat_estouro_sla,
    num_duracao,
    duracao_sla,
    titulo,
    sla_violado
FROM painel_monitoracao_administrativo
WHERE dat_abertura >= date_add('month', -6, current_date)
  AND (
        (classificacao = 'Incidente' AND severidade IN ('3 - Média', '4 - Alta', '5 - Crítica'))
     OR (classificacao = 'Solicitação' AND severidade = '4 - Alta')
      )
ORDER BY num_chamado DESC
"""

logger = logging.getLogger()
logger.setLevel(logging.INFO)

CHUNK_SIZE = 50000  # número de registros por arquivo

def lambda_handler(event, context):
    logger.info("Iniciando execução Athena...")

    exec_id = athena.start_query_execution(
        QueryString=QUERY,
        QueryExecutionContext={"Database": DATABASE},
        ResultConfiguration={"OutputLocation": OUTPUT_BUCKET},
        WorkGroup=WORKGROUP
    )["QueryExecutionId"]

    while True:
        status = athena.get_query_execution(QueryExecutionId=exec_id)["QueryExecution"]["Status"]["State"]
        if status in ["SUCCEEDED", "FAILED", "CANCELLED"]:
            break
        time.sleep(3)

    if status != "SUCCEEDED":
        raise Exception(f"Athena query failed: {status}")

    logger.info("Consulta Athena concluída com sucesso.")

    results = []
    next_token = None
    headers = []
    total_count = 0
    part_number = 1

    while True:
        if next_token:
            response = athena.get_query_results(QueryExecutionId=exec_id, NextToken=next_token)
        else:
            response = athena.get_query_results(QueryExecutionId=exec_id)

        if not headers:
            headers = [col["Label"] for col in response["ResultSet"]["ResultSetMetadata"]["ColumnInfo"]]

        for row in response["ResultSet"]["Rows"][1:]:
            data = [v.get("VarCharValue") for v in row["Data"]]
            results.append(dict(zip(headers, data)))
            total_count += 1

            # Salva em partes
            if len(results) >= CHUNK_SIZE:
                key = f"{CACHE_PREFIX}{part_number:03d}.json"
                s3.put_object(
                    Bucket=CACHE_BUCKET,
                    Key=key,
                    Body=json.dumps(results, ensure_ascii=False),
                    ContentType="application/json"
                )
                logger.info(f"Salvou {len(results)} registros em {key}")
                results.clear()
                part_number += 1

        next_token = response.get("NextToken")
        if not next_token:
            break

    # salva o restante
    if results:
        key = f"{CACHE_PREFIX}{part_number:03d}.json"
        s3.put_object(
            Bucket=CACHE_BUCKET,
            Key=key,
            Body=json.dumps(results, ensure_ascii=False),
            ContentType="application/json"
        )
        logger.info(f"Salvou {len(results)} registros finais em {key}")

    logger.info(f"Processo concluído. Total de {total_count} registros em {part_number} partes.")

    return {"status": "ok", "total": total_count, "parts": part_number}
